{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "\n",
    "<h1 align=center><font size = 5>Regresi√≥n log√≠stica con Python</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "En este cuaderno aprender√° sobre regresi√≥n log√≠stica y luego crear√° un modelo para una empresa de telecomunicaciones, cuya finalidad ser√° predecir casos en los que los clientes vayan a pasarse a una empresa competidora, de manera tal que puedan tomar medidas para retener a los clientes..\n",
    "\n",
    "\n",
    "<a id=\"ref1\"></a>\n",
    "## ¬øEn qu√© se diferencian la regresi√≥n lineal y la log√≠stica?\n",
    "\n",
    "Si bien la regresi√≥n lineal es adecuada para estimar valores continuos (p. ej., el precio de una casa), no es la mejor herramienta para predecir la clase a la que pertenece un dato observado. Para estimar la clase de un dato, necesitamos alg√∫n tipo de orientaci√≥n en cuanto a cu√°l ser√≠a **la clase m√°s probable [most probable class]** Para eso, usamos la **Regresi√≥n Log√≠stica [Logistic Regression]**.\n",
    "\n",
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "<font size = 3><strong>Para recordar sobre la regresi√≥n lineal:</strong></font>\n",
    "<br>\n",
    "<br>\n",
    "Como sabr√°, __la regresi√≥n lineal__ halla una funci√≥n que relaciona una variable dependiente continua, __y__, con algunos predictores (variables independientes __x1__, __x2__, etc.). Por ejemplo, la regresi√≥n lineal simple supone una funci√≥n con la siguiente forma:\n",
    "<br><br>\n",
    "$$\n",
    "y = ùúÉ0 + ùúÉ1 * x1 + ùúÉ2 * x2 +...\n",
    "$$\n",
    "<br>\n",
    "y halla los valores de los par√°metros _Œ∏0_, _Œ∏1_, _ùúÉ2_, etc., donde el t√©rmino _ùúÉ0_ es la ‚Äúordenada al origen‚Äù [intercept]. Por lo general se puede representar as√≠: \n",
    "<br><br>\n",
    "$$\n",
    "‚Ñé_Œ∏(ùë•) = ùúÉ^TX\n",
    "$$\n",
    "<p></p>\n",
    "\n",
    "</div>\n",
    "\n",
    "La regresi√≥n log√≠stica es una variaci√≥n de la regresi√≥n lineal, y es √∫til cuando la variable dependiente observada, _y_, es categ√≥rica. Produce una f√≥rmula que predice la probabilidad de la etiqueta de la clase como funci√≥n de las variables independientes.\n",
    "\n",
    "La regresi√≥n log√≠stica ajusta a una curva especial con forma de ‚Äús‚Äù. Para ello, toma la regresi√≥n lineal y transforma la estimaci√≥n num√©rica en una probabilidad con la siguiente funci√≥n, que se denomina funci√≥n sigmoidea ùúé:\n",
    "\n",
    "$$\n",
    "‚Ñé_Œ∏(ùë•) = ùúé({Œ∏^TX}) =  \\frac {e^{(Œ∏0 + Œ∏1 * x1 + Œ∏2 * x2 +...)}}{1 + e^{(Œ∏0 + Œ∏1 * x1 + Œ∏2 * x2 +...)}}\n",
    "$$\n",
    "O bien:\n",
    "$$\n",
    "ProbabilityOfaClass_1 =  P(Y=1|X) = ùúé({Œ∏^TX}) = \\frac{e^{Œ∏^TX}}{1+e^{Œ∏^TX}} \n",
    "$$\n",
    "\n",
    "En esta ecuaci√≥n, ${Œ∏^TX}$ es el resultado de la regresi√≥n (la suma de las variables ponderadas por los coeficientes), `exp` es la funci√≥n exponencial y $ùúé(Œ∏^TX)$ es la funci√≥n sigmoidea o [funci√≥n log√≠stica](http://en.wikipedia.org/wiki/Logistic_function), tambi√©n llamada curva log√≠stica. Es una figura con forma de ‚ÄúS‚Äù com√∫n (curva sigmoidea).\n",
    "\n",
    "En resumen, la regresi√≥n log√≠stica transforma los datos de entrada por medio de una funci√≥n log√≠stica o sigmoidea, pero luego trata el resultado como una probabilidad:\n",
    "\n",
    "<img\n",
    "src=\"https://ibm.box.com/shared/static/kgv9alcghmjcv97op4d6onkyxevk23b1.png\" width = \"400\" align = \"center\">\n",
    "\n",
    "\n",
    "El objetivo del algoritmo de __regrusi√≥n log√≠stica [Logistic Regression]__ es hallar los par√°metros √≥ptimos Œ∏ para ‚Ñé_Œ∏(ùë•) = ùúé({Œ∏^TX}), de manera tal que el modelo realice la mejor predicci√≥n en cuanto a la clase a la que pertenece cada caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P√©rdida de clientes con regresi√≥n log√≠stica\n",
    "Una empresa de telecomunicaciones est√° preocupada por la cantidad de clientes que cancelan sus servicios de l√≠nea fija y contratan a empresas competidoras que ofrecen servicio por cable. Necesita saber qu√© clientes la abandonar√°n por un competidor. Imag√≠nese que usted es un analista que trabaja en esta empresa y tiene que averiguar qui√©nes cancelan el servicio y por qu√©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Primero importemos las bibliotecas necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Acerca del conjunto de datos\n",
    "Utilizaremos un conjunto de datos de telecomunicaciones para predecir la p√©rdida de clientes. Se trata de datos hist√≥ricos de clientes y cada fila representa a un cliente. Los datos son relativamente f√°ciles de entender, y es posible que obtenga conocimientos que pueda usar de inmediato. Por lo general, es menos costoso mantener clientes que captar nuevos, por lo que este an√°lisis se enfocar√° en predecir qui√©nes continuar√°n siendo clientes de la empresa.\n",
    "\n",
    "Este conjunto de datos proporciona informaci√≥n que ayuda a predecir el comportamiento para retener clientes. Puede analizar todos los datos pertinentes sobre los clientes y desarrollar programas centrados en retenerlos.\n",
    "\n",
    "El conjunto de datos incluye informaci√≥n sobre lo siguiente:\n",
    "- Clientes perdidos en el √∫ltimo mes. La columna se llama Perdidos [Churn].\n",
    "- Servicios contratados por cada cliente (tel√©fono, varias l√≠neas, internet, seguridad en l√≠nea, copias de seguridad en l√≠nea, protecci√≥n de dispositivos, servicio t√©cnico y televisi√≥n y pel√≠culas por internet).\n",
    "- Informaci√≥n de cuentas de clientes (cu√°nto tiempo hace que son clientes, contrato, m√©todo de pago, factura electr√≥nica, cargos mensuales y cargos totales).\n",
    "- Informaci√≥n demogr√°fica sobre los clientes (sexo, rango de edad y si tienen pareja o personas a su cargo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "###  Carga de datos de Telco Churn\n",
    "Telco Churn es un archivo de datos hipot√©ticos sobre los esfuerzos de una empresa de telecomunicaciones por reducir la p√©rdida de clientes. Cada caso corresponde a un cliente aparte y registra diversos datos demogr√°ficos y de uso de servicios. Antes de poder trabajar con los datos, debe usar el URL para obtener el archivo ChurnData.csv.\n",
    "\n",
    "Usaremos `!wget` para descargar los datos de IBM Object Storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Click here and press Shift+Enter\n",
    "!wget -O ChurnData.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/ChurnData.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__¬øSab√≠a usted?__ Al usar aprendizaje autom√°tico, es probable que trabaje con grandes conjuntos de datos. Como empresa, ¬ød√≥nde puede alojar sus datos? IBM ofrece una oportunidad inigualable para empresas, con 10 TB de almacenamiento en IBM Cloud Object Storage: [Reg√≠strese ahora gratis](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Carga de datos del archivo CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv(\"ChurnData.csv\")\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento y selecci√≥n de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionemos algunas caracter√≠sticas para el modelado. Adem√°s, cambiamos el tipo de datos objetivo a enteros, porque es un requisito del algoritmo de skitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
    "churn_df['churn'] = churn_df['churn'].astype('int')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": true,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Pr√°ctica\n",
    "¬øCu√°ntas filas y columnas hay en total en este conjunto de datos? ¬øCu√°les son los nombres de las columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos X e y para nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(churn_df['churn'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adem√°s, normalizamos el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos de entrenamiento/prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos nuestro conjunto de datos en conjunto de entrenamiento y conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado (regresi√≥n log√≠stica con scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyamos nuestro modelo con __LogisticRegression__ from Scikit-learn del paquete scikit-learn. Esta funci√≥n implementa regresi√≥n log√≠stica y puede usar diferentes optimizadores num√©ricos para hallar par√°metros, entre ellos solucionadores ‚Äúnewton-cg‚Äù, ‚Äúlbfgs‚Äù, ‚Äúliblinear‚Äù, ‚Äúsag‚Äù y ‚Äúsaga‚Äù. En internet hay una gran cantidad de informaci√≥n sobre las ventajas y desventajas de estos optimizadores.\n",
    "\n",
    "La versi√≥n de regresi√≥n log√≠stica de scikit-learn admite regularizaci√≥n. La regularizaci√≥n es una t√©cnica que se emplea para resolver el problema de exceso de ajuste en modelos de aprendizaje autom√°tico.\n",
    "El par√°metro __C_ indica la __fuerza de la inversa de la regularizaci√≥n [inverse of regularization strength]__ que debe ser un valor de punto flotante. Cuanto menor es el valor, mayor es la regularizaci√≥n. \n",
    "Ahora ajustemos el modelo con el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos predecir con nuestro conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__predict_proba__  arroja estimaciones de todas las clases, ordenadas por la etiqueta de las clases. Entonces, la primera columna es la probabilidad de la clase 1, P(Y=1|X), y la segunda columna es la probabilidad de la clase 0, P(Y=0|X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √çndice de jaccard\n",
    "Intentemos evaluar la exactitud con el √≠ndice de Jaccard. Podemos definir este √≠ndice como el tama√±o de la intersecci√≥n dividido por el tama√±o de la uni√≥n de dos conjuntos de etiquetas. Si todo el conjunto de etiquetas predichas de una muestra coincide con el conjunto real de etiquetas, la precisi√≥n del subconjunto es de 1.0; si no, es de 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusi√≥n\n",
    "Otra manera de evaluar la exactitud de clasificadores es observar la __Matriz de confusi√≥n [confusion matrix]__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe la primera fila. La primera fila es de los clientes cuyo valor real de p√©rdida en el conjunto de prueba es 1. Al calcular sobre un total de 40 clientes, el valor de p√©rdida de 15 de ellos es 1. De esos 15, el clasificador predijo correctamente 6 de ellos como 1, y 9 de ellos como 0.\n",
    "\n",
    "Significa que, para 6 clientes, el valor de p√©rdida real fue 1 en el conjunto de prueba, y el clasificador tambi√©n predijo correctamente que ser√≠a 1. Sin embargo, aunque la etiqueta real de 9 clientes fue 1, el clasificador predijo que ser√≠a 0, lo cual no es muy bueno. Podemos considerarlo como error del modelo para la primera fila.\n",
    "\n",
    "¬øY qu√© ocurre con los clientes con valor de p√©rdida igual a cero? Observemos la segunda fila. Parece que hubo 25 clientes cuyo valor de p√©rdida fue 0.\n",
    "\n",
    "El clasificador predijo correctamente 24 de ellos como 0, y 1 de ellos incorrectamente como 1. Hizo un buen trabajo de predicci√≥n de clientes con valor de p√©rdida igual a 0. Algo que tiene de bueno la matriz de confusi√≥n es que muestra la capacidad del modelo de predecir o separar las clases correctamente. En el caso espec√≠fico de clasificadores binarios, como el de este ejemplo, podemos interpretar esos n√∫meros como la cantidad de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la cantidad que haya en cada secci√≥n, podemos calcular la precisi√≥n y la exhaustividad de cada etiqueta:\n",
    "\n",
    "\n",
    "- La __Precisi√≥n__ es una medida de la exactitud cuando se ha predicho la etiqueta de una clase. Se define de la siguiente manera: precisi√≥n = VP / (VP + FP)\n",
    "\n",
    "- La __Exhaustividad__ es la raz√≥n de verdaderos positivos. Se define as√≠: Exhaustividad = VP / (VP + FN)\n",
    "\n",
    "    \n",
    "Por lo tanto, podemos calcular la precisi√≥n y la exhaustividad de cada clase.\n",
    "\n",
    "__Valor F1:__\n",
    "Ahora estamos en condiciones de calcular los valores F1 de cada etiqueta a partir de la precisi√≥n y la exhaustividad de dicha etiqueta.\n",
    "\n",
    "El valor F1 es el promedio arm√≥nico de la precisi√≥n y la exhaustividad. Alcanza su mejor valor en 1 (precisi√≥n y exhaustividad perfectas), y el peor, en 0. Es una buena manera de mostrar que un clasificador tiene un buen valor tanto de exhaustividad como de precisi√≥n.\n",
    "\n",
    "Y, por √∫ltimo, podemos decir que la exactitud promedio de este clasificador es el promedio del valor F1 de ambas etiquetas, que en nuestro caso es 0.72.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log loss\n",
    "Ahora probemos evaluar con __log loss__ En la regresi√≥n log√≠stica, la informaci√≥n de salida puede ser la probabilidad de que s√≠ haya una p√©rdida de cliente (o de que sea igual a 1). Esa probabilidad es un valor entre 0 y 1. Log loss (p√©rdida logar√≠tmica) mide el desempe√±o de un clasificador cuando la informaci√≥n predicha es un valor de probabilidad entre 0 y 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, yhat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√°ctica\n",
    "Intente volver a construir un modelo de regresi√≥n log√≠stica para el mismo conjunto de datos, pero esta vez use diferentes valores de __solucionador [solver]__ y __regularizaci√≥n [regulization]__? ¬øCu√°l es el nuevo valor de  __logLoss__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presione doble clic __aqu√≠__ para ver la respuesta.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "    \n",
    "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_train,y_train)\n",
    "yhat_prob2 = LR2.predict_proba(X_test)\n",
    "print (\"LogLoss: : %.2f\" % log_loss(y_test, yhat_prob2))\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## ¬øDesea saber m√°s?\n",
    "\n",
    "IBM SPSS Modeler es una plataforma de an√°lisis completa que tiene muchos algoritmos de aprendizaje autom√°tico. Ha sido dise√±ada para aportar inteligencia predictiva a las decisiones que toman personas, grupos, sistemas, su empresa como conjunto. Este curso le permite acceder a una evaluaci√≥n gratuita, disponible en este enlace: [SPSS Modeler](http://cocl.us/ML0101EN-SPSSModeler).\n",
    "\n",
    "Tambi√©n puede usar Watson Studio para ejecutar estos cuadernos m√°s r√°pido con conjuntos de datos m√°s grandes. Watson Studio es la soluci√≥n de IBM en la nube n√∫mero uno para cient√≠ficos de datos, construida por cient√≠ficos de datos. Con los cuadernos Jupyter, RStudio, Apache Spark y otras bibliotecas populares preempaquetadas en la nube, Watson Studio hace posible que los cient√≠ficos de datos colaboren en sus proyectos sin necesidad de instalar nada. S√∫mese hoy mismo a la comunidad de usuarios de Watson Studio, que crece cada d√≠a m√°s, con una cuenta gratuita en [Watson Studio](https://cocl.us/ML0101EN_DSX)\n",
    "\n",
    "### ¬°Gracias por completar esta lecci√≥n!\n",
    "\n",
    "Cuaderno creado por: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>\n",
    "\n",
    "<hr>\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). Este cuaderno y su c√≥digo fuente se difunden de conformidad con los t√©rminos de la [licencia del MIT](https://bigdatauniversity.com/mit-license/).‚Äã"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
