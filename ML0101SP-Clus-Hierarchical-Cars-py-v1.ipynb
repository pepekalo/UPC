{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "\n",
    "# <center>Agrupamiento jerárquico</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido al laboratorio de agrupamiento jerárquico con Python usando SciPy y el paquete Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Agrupamiento jerárquico aglomerativo\n",
    "\n",
    "Veremos una técnica de agrupamiento, que es el <b>agrupamiento jerárquico aglomerativo</b>. Recuerde que el aglomerativo es el enfoque de abajo hacia arriba. <br> <br>\n",
    "En este laboratorio veremos el agrupamiento aglomerativo, que es más utilizado que el agrupamiento divisivo.  <br> <br>\n",
    "Como criterio de enlace utilizaremos el enlace completo.  <br>\n",
    "<b> <i> NOTA: ¡también puede intentar usar enlace promedio donde se utilizaría enlace completo para ver la diferencia! </i> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import ndimage \n",
    "from scipy.cluster import hierarchy \n",
    "from scipy.spatial import distance_matrix \n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn import manifold, datasets \n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.datasets.samples_generator import make_blobs \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Generación de datos aleatorios\n",
    "Usaremos la clase  <b>make_blobs</b> para generar un conjunto de datos. <br> <br>\n",
    "Ingrese los siguientes parámetros en make_blobs:\n",
    "<ul>\n",
    "    <li> <b>n_samples</b>: es la cantidad total de puntos dividida por igual entre clústeres. </li>\n",
    "    <ul> <li> Elija un número de 10 a 1500. </li> </ul>\n",
    "    <li> <b>centers</b>: es la cantidad de centros que se generarán, o la ubicación fija de los centros. </li>\n",
    "    <ul> <li> Seleccione arreglos de coordenadas x,y para generar los centros. Use entre 1 y 10 centros (ej.: centers=[[1,1], [2,5]]) </li> </ul>\n",
    "    <li> <b>cluster_std</b>: la desviación estándar de los clústeres. Cuanto mayor sea el número, más separados estarán los clústeres.</li>\n",
    "    <ul> <li> Elija un número entre 0.5-1.5 </li> </ul>\n",
    "</ul> <br>\n",
    "Guarde el resultado en <b>X1</b> e <b>y1</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=50, centers=[[4,4], [-2, -1], [1, 1], [10,4]], cluster_std=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibuje el diagrama de dispersión de los datos generados en forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Agrupamiento aglomerativo\n",
    "Para comenzar, agruparemos los datos aleatorios que acabamos de crear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase <b> Agrupamiento aglomerativo [Agglomerative Clustering] </b> requiere dos valores de entrada:\n",
    "<ul>\n",
    "    <li> <b>n_clusters</b>: cantidad de clústeres que se formarán y cantidad de baricentros que se generarán. </li>\n",
    "    <ul> <li> El valor será: 4 </li> </ul>\n",
    "    <li> <b>linkage</b>: qué criterio de enlace se utilizará. El criterio de enlace determina qué distancia usar entre conjuntos de observaciones. El algoritmo combinará los pares de clústeres que minimicen este criterio. </li>\n",
    "    <ul> \n",
    "        <li> El valor será: “complete” </li> \n",
    "        <li> <b>Nota</b>: se recomienda probar también todo con “average” (promedio) </li>\n",
    "    </ul>\n",
    "</ul> <br>\n",
    "Guarde el resultado en una variable llamada <b> agglom </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters = 4, linkage = 'average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste el modelo con  <b> X2 </b> e <b> y2 </b> de los datos generados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agglom.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ejecute el código siguiente para mostrar el agrupamiento! <\\br>\n",
    "Recuerde leer el código y los comentarios para entender mejor cómo funciona la representación gráfica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure of size 6 inches by 4 inches.\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# These two lines of code are used to scale the data points down,\n",
    "# Or else the data points will be scattered very far apart.\n",
    "\n",
    "# Create a minimum and maximum range of X1.\n",
    "x_min, x_max = np.min(X1, axis=0), np.max(X1, axis=0)\n",
    "\n",
    "# Get the average distance for X1.\n",
    "X1 = (X1 - x_min) / (x_max - x_min)\n",
    "\n",
    "# This loop displays all of the datapoints.\n",
    "for i in range(X1.shape[0]):\n",
    "    # Replace the data points with their respective cluster value \n",
    "    # (ex. 0) and is color coded with a colormap (plt.cm.spectral)\n",
    "    plt.text(X1[i, 0], X1[i, 1], str(y1[i]),\n",
    "             color=plt.cm.nipy_spectral(agglom.labels_[i] / 10.),\n",
    "             fontdict={'weight': 'bold', 'size': 9})\n",
    "    \n",
    "# Remove the x ticks, y ticks, x and y axis\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "#plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "# Display the plot of the original data before clustering\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='.')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dendrograma asociado al agrupamiento jerárquico aglomerativo\n",
    "Recuerde que la <b>matriz de distancias [distance matrix]</b> contiene la distancia desde cada punto a todos los demás puntos del conjunto de datos</b>. <br> \n",
    "Use la función <b>distance_matrix</b>, que requiere <b>dos valores de entrada [two inputs]</b>. Use la matriz de características, <b> X2 </b>, como ambos valores de entrada y guarde la matriz de distancia en una variable con el nombre <b> dist_matrix </b> <br> <br>.\n",
    "\n",
    "Recuerde que los valores de distancia son simétricos y en la diagonal hay ceros. Esta es una manera de asegurarse de que la matriz sea correcta. \n",
    "<br>(Imprima en pantalla dist_matrix para asegurarse de que sea correcta) [(print out dist_matrix to make sure it's correct)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix(X1,X1) \n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use la clase <b> linkage </b> (enlace) de la jerarquía para pasar como parámetros:\n",
    "<ul>\n",
    "    <li> la matriz de distancias </li>\n",
    "    <li> 'complete' para enlace completo </li>\n",
    "</ul> <br>\n",
    "Guarde el resultado en una variable llamada <b> Z </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = hierarchy.linkage(dist_matrix, 'complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, los agrupamientos jerárquicos se representan visualmente como dendrogramas, como se muestra en la siguiente celda. Cada combinación está representada por una línea horizontal. La coordenada y de la línea horizontal es la similitud de los dos clústeres que se combinaron, donde las ciudades se ven como clústeres de un solo punto. Al avanzar de la capa más baja al nodo más alto, el dendrograma nos permite reconstruir el historial de combinaciones que dio como resultado el agrupamiento representado.\n",
    "\n",
    "A continuación guardaremos el dendrograma en una variable llamada <b>dendro</b>. Al hacer esto, también se mostrará el dendrograma. Usamos la clase <b> dendrogram </b> de la jerarquía para pasar como parámetro:\n",
    "<ul> <li> Z </li> </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro = hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica\n",
    "Para nuestro caso usamos enlace   __completo [complete]__ cambie a enlace  __promedio [average]__ para ver cómo varía el dendrograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haga doble clic __aquí [here]__ para ver la solución.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "    \n",
    "Z = hierarchy.linkage(dist_matrix, 'average')\n",
    "dendro = hierarchy.dendrogram(Z)\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Agrupamiento en un conjunto de datos de vehículos\n",
    "\n",
    "Suponga que una empresa automotriz ha desarrollado prototipos de un nuevo vehículo. Antes de incorporar el nuevo modelo a su línea, el fabricante desea determinar qué vehículos del mercado se parecen más a los prototipos (es decir, cómo se pueden agrupar los vehículos, qué grupo es el más similar al modelo y, por lo tanto, contra qué modelos competirán).\n",
    "\n",
    "Nuestro objetivo es usar métodos de agrupamiento para hallar los clústeres de vehículos más característicos. Esto servirá como resumen de los vehículos actuales y ayudará al fabricante a tomar decisiones sobre nuevos modelos de manera simple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de los datos\n",
    "Para descargar los datos, usaremos **`!wget`**. Usaremos  `!wget` para descargar los datos de IBM Object Storage. \n",
    "__¿Sabía usted?__ Al usar aprendizaje automático, es probable que trabaje con grandes conjuntos de datos. Como empresa, ¿dónde puede alojar sus datos? IBM ofrece una oportunidad inigualable para empresas, con 10 TB de almacenamiento en IBM Cloud Object Storage: [Regístrese ahora gratis](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O cars_clus.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cars_clus.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los datos\n",
    "Leamos el conjunto de datos para ver qué características de los modelos actuales ha reunido el fabricante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'cars_clus.csv'\n",
    "\n",
    "#Read csv\n",
    "pdf = pd.read_csv(filename)\n",
    "print (\"Shape of dataset: \", pdf.shape)\n",
    "\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las características son: precio en dólares [price], tamaño del motor [engine_s], potencia en caballos de fuerza [horsepow], distancia entre ejes [wheelbas], ancho [width], longitud [length], peso en vacío [curb_wgt], capacidad del tanque de combustible [fuel_cap] y eficiencia de uso del combustible [mpg]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de los datos\n",
    "Para limpiar el conjunto de datos, quitemos las columnas que tienen valor nulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of dataset before cleaning: \", pdf.size)\n",
    "pdf[[ 'sales', 'resale', 'type', 'price', 'engine_s',\n",
    "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
    "       'mpg', 'lnsales']] = pdf[['sales', 'resale', 'type', 'price', 'engine_s',\n",
    "       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n",
    "       'mpg', 'lnsales']].apply(pd.to_numeric, errors='coerce')\n",
    "pdf = pdf.dropna()\n",
    "pdf = pdf.reset_index(drop=True)\n",
    "print (\"Shape of dataset after cleaning: \", pdf.size)\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de características\n",
    "Seleccionemos nuestro conjunto de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset = pdf[['engine_s',  'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización\n",
    "Ahora podemos normalizar el conjunto de características. __MinMaxScaler__ transforma las características; modifica cada una de ellas para ajustarla a un rango dado. El valor predeterminado es (0, 1). Es decir, este estimador cambia la escala y convierte cada característica en forma individual, de manera tal que quede entre cero y uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = featureset.values #returns a numpy array\n",
    "min_max_scaler = MinMaxScaler()\n",
    "feature_mtx = min_max_scaler.fit_transform(x)\n",
    "feature_mtx [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupamiento con Scipy\n",
    "En esta parte usamos el paquete Scipy para agrupar el conjunto de datos:\n",
    "En primer lugar, calculamos la matriz de distancias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "leng = feature_mtx.shape[0]\n",
    "D = scipy.zeros([leng,leng])\n",
    "for i in range(leng):\n",
    "    for j in range(leng):\n",
    "        D[i,j] = scipy.spatial.distance.euclidean(feature_mtx[i], feature_mtx[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el agrupamiento aglomerativo, el algoritmo debe actualizar la matriz de distancias para reflejar la distancia del clúster recién formado con respecto a los demás clústeres del bosque. Scipy admite los siguientes métodos para calcular la distancia entre el clúster recién formado y cada uno:\n",
    "- single (individual)\n",
    "- complete (completo)\n",
    "- average (promedio)\n",
    "- weighted (ponderado)\n",
    "- centroid (baricentro)\n",
    "\n",
    "Usamos __complete__ para nuestro caso, pero si lo desea, cámbielo para ver cómo varían los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import scipy.cluster.hierarchy\n",
    "Z = hierarchy.linkage(D, 'complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Básicamente, el agrupamiento jerárquico no exige una cantidad predefinida de clústeres. Sin embargo, para algunos usos queremos una partición de clústeres disjuntos, como en el agrupamiento particional. \n",
    "Puede usar una línea de corte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "max_d = 3\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, puede determinar la cantidad de clústeres de manera directa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "k = 5\n",
    "clusters = fcluster(Z, k, criterion='maxclust')\n",
    "clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, dibujemos el dendrograma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pylab.figure(figsize=(18,50))\n",
    "def llf(id):\n",
    "    return '[%s %s %s]' % (pdf['manufact'][id], pdf['model'][id], int(float(pdf['type'][id])) )\n",
    "    \n",
    "dendro = hierarchy.dendrogram(Z,  leaf_label_func=llf, leaf_rotation=0, leaf_font_size =12, orientation = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupamiento con scikit-learn\n",
    "Hagámoslo de nuevo, pero esta vez con el paquete scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix(feature_mtx,feature_mtx) \n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar la función de agrupamiento aglomerativo AgglomerativeClustering de la biblioteca scikit-learn para agrupar el conjunto de datos. AgglomerativeClustering realiza un agrupamiento jerárquico con el enfoque de abajo hacia arriba. El criterio de enlace determina la métrica que se utiliza para la estrategia de combinación:\n",
    "- El método de Ward minimiza la suma de los cuadrados de las diferencias entre todos los clústeres. Busca minimizar la varianza y en ese sentido se parece a la función objetivo de k medias, pero tratada con un enfoque jerárquico aglomerativo.\n",
    "- El enlace máximo o completo minimiza la distancia máxima entre observaciones de pares de clústeres.\n",
    "- El enlace promedio minimiza el promedio de las distancias entre todas las observaciones de pares de clústeres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters = 6, linkage = 'complete')\n",
    "agglom.fit(feature_mtx)\n",
    "agglom.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos agregar un nuevo campo a nuestra hoja de datos para mostrar el clúster de cada fila:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['cluster_'] = agglom.labels_\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "n_clusters = max(agglom.labels_)+1\n",
    "colors = cm.rainbow(np.linspace(0, 1, n_clusters))\n",
    "cluster_labels = list(range(0, n_clusters))\n",
    "\n",
    "# Create a figure of size 6 inches by 4 inches.\n",
    "plt.figure(figsize=(16,14))\n",
    "\n",
    "for color, label in zip(colors, cluster_labels):\n",
    "    subset = pdf[pdf.cluster_ == label]\n",
    "    for i in subset.index:\n",
    "            plt.text(subset.horsepow[i], subset.mpg[i],str(subset['model'][i]), rotation=25) \n",
    "    plt.scatter(subset.horsepow, subset.mpg, s= subset.price*10, c=color, label='cluster'+str(label),alpha=0.5)\n",
    "#    plt.scatter(subset.horsepow, subset.mpg)\n",
    "plt.legend()\n",
    "plt.title('Clusters')\n",
    "plt.xlabel('horsepow')\n",
    "plt.ylabel('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observar, estamos viendo la distribución de cada clúster mediante el diagrama de dispersión, pero no queda muy claro cuál es el baricentro de cada clúster. Además, hay dos tipos de vehículos en nuestro conjunto de datos: “camioneta” (con valor 1 en la columna de tipo) y “automóvil” (con valor 1 en la columna de tipo). Los usamos para distinguir entre clases y resumir el clúster. Primero contamos la cantidad de casos que hay en cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.groupby(['cluster_','type'])['cluster_'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora prestamos atención a las características de cada clúster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cars = pdf.groupby(['cluster_','type'])['horsepow','engine_s','mpg','price'].mean()\n",
    "agg_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Es evidente que tenemos tres clústeres principales que contienen la mayoría de los vehículos.\n",
    "__Automóviles [Cars]__:\n",
    "- Clúster 1: con valor alto de eficiencia de uso del combustible y bajo en cuanto a potencia.\n",
    "- Clúster 2: con buena potencia y eficiencia de uso del combustible, pero a un precio superior a la media.\n",
    "- Clúster 3: con valor bajo en términos de eficiencia, mucha potencia y el precio más alto.\n",
    "\n",
    "__Camionetas [Trucks]:\n",
    "- Clúster 1: con casi el valor más alto de eficiencia entre las camionetas, y el más bajo en potencia y precio.\n",
    "- Clúster 2: con eficiencia casi baja y potencia media, pero precio superior al promedio.\n",
    "- Clúster 3: con buena eficiencia y potencia, precio bajo.\n",
    "\n",
    "Observe que no usamos el tipo y el precio de los vehículos en el proceso de agrupamiento, pero el agrupamiento jerárquico pudo crear los clústeres y distinguirlos con una exactitud bastante alta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "for color, label in zip(colors, cluster_labels):\n",
    "    subset = agg_cars.loc[(label,),]\n",
    "    for i in subset.index:\n",
    "        plt.text(subset.loc[i][0]+5, subset.loc[i][2], 'type='+str(int(i)) + ', price='+str(int(subset.loc[i][3]))+'k')\n",
    "    plt.scatter(subset.horsepow, subset.mpg, s=subset.price*20, c=color, label='cluster'+str(label))\n",
    "plt.legend()\n",
    "plt.title('Clusters')\n",
    "plt.xlabel('horsepow')\n",
    "plt.ylabel('mpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Desea saber más?\n",
    "\n",
    "IBM SPSS Modeler es una plataforma de análisis completa que tiene muchos algoritmos de aprendizaje automático. Ha sido diseñada para aportar inteligencia predictiva a las decisiones que toman personas, grupos, sistemas, su empresa como conjunto. Este curso le permite acceder a una evaluación gratuita, disponible en este enlace: [SPSS Modeler](http://cocl.us/ML0101EN-SPSSModeler).\n",
    "\n",
    "También puede usar Watson Studio para ejecutar estos cuadernos más rápido con conjuntos de datos más grandes. Watson Studio es la solución de IBM en la nube número uno para científicos de datos, construida por científicos de datos. Con los cuadernos Jupyter, RStudio, Apache Spark y otras bibliotecas populares preempaquetadas en la nube, Watson Studio hace posible que los científicos de datos colaboren en sus proyectos sin necesidad de instalar nada. Súmese hoy mismo a la comunidad de usuarios de Watson Studio, que crece cada día más, con una cuenta gratuita en [Watson Studio](https://cocl.us/ML0101EN_DSX)\n",
    "\n",
    "### Thanks for completing this lesson!\n",
    "\n",
    "Cuaderno creado por: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>\n",
    "\n",
    "<hr>\n",
    "Copyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). Este cuaderno y su código fuente se difunden de conformidad con los términos de la [licencia del MIT](https://bigdatauniversity.com/mit-license/).​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
